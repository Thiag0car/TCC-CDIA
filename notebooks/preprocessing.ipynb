{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring solution for dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames(video_path, output_folder, interval_seconds=5):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_rate = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    interval_frames = frame_rate * interval_seconds\n",
    "\n",
    "    frame_count = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        if frame_count % interval_frames == 0:\n",
    "            output_filename = f\"{output_folder}/frame_{frame_count}.jpg\"\n",
    "            cv2.imwrite(output_filename, frame)\n",
    "            print(f\"Saved {output_filename}\")\n",
    "        \n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8m.pt to yolov8m.pt...\n",
      "100%|██████████| 49.7M/49.7M [00:25<00:00, 2.07MB/s]\n"
     ]
    }
   ],
   "source": [
    "model = YOLO('yolov8m.pt')\n",
    "image = '../data/processed/frames/frame_0.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-29 16:57:00.951308: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\n",
      "image 1/1 /home/joaotaves/repos/TCC-CDIA/notebooks/../data/processed/frames/frame_0.jpg: 384x640 2 persons, 1 car, 1 truck, 1 potted plant, 114.8ms\n",
      "Speed: 4.6ms preprocess, 114.8ms inference, 63.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ultralytics.yolo.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.yolo.engine.results.Boxes object\n",
      "keypoints: None\n",
      "keys: ['boxes']\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "orig_img: array([[[ 50,  71,  79],\n",
      "        [ 45,  66,  74],\n",
      "        [ 25,  48,  56],\n",
      "        ...,\n",
      "        [ 60,  92, 115],\n",
      "        [ 67,  99, 122],\n",
      "        [ 63,  97, 120]],\n",
      "\n",
      "       [[ 44,  65,  73],\n",
      "        [ 42,  63,  71],\n",
      "        [ 23,  46,  54],\n",
      "        ...,\n",
      "        [ 63,  95, 118],\n",
      "        [ 62,  94, 117],\n",
      "        [ 58,  92, 115]],\n",
      "\n",
      "       [[ 40,  61,  69],\n",
      "        [ 37,  58,  66],\n",
      "        [ 18,  41,  49],\n",
      "        ...,\n",
      "        [ 54,  86, 109],\n",
      "        [ 40,  72,  95],\n",
      "        [ 26,  60,  83]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 88, 101,  99],\n",
      "        [ 88, 101,  99],\n",
      "        [ 88, 100, 100],\n",
      "        ...,\n",
      "        [ 78,  90,  94],\n",
      "        [ 78,  90,  94],\n",
      "        [ 78,  90,  94]],\n",
      "\n",
      "       [[ 90, 101,  99],\n",
      "        [ 90, 101,  99],\n",
      "        [ 90, 100, 100],\n",
      "        ...,\n",
      "        [ 78,  90,  94],\n",
      "        [ 78,  90,  96],\n",
      "        [ 78,  90,  96]],\n",
      "\n",
      "       [[ 90, 101,  99],\n",
      "        [ 90, 101,  99],\n",
      "        [ 90, 100, 100],\n",
      "        ...,\n",
      "        [ 78,  90,  94],\n",
      "        [ 78,  90,  96],\n",
      "        [ 78,  90,  96]]], dtype=uint8)\n",
      "orig_shape: (720, 1280)\n",
      "path: '/home/joaotaves/repos/TCC-CDIA/notebooks/../data/processed/frames/frame_0.jpg'\n",
      "probs: None\n",
      "save_dir: None\n",
      "speed: {'preprocess': 4.610300064086914, 'inference': 114.80498313903809, 'postprocess': 62.99400329589844}]\n"
     ]
    }
   ],
   "source": [
    "results = model.predict(image)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(image_path, model = YOLO('yolov8m.pt')):\n",
    "    results = model.predict(image_path)\n",
    "    result = results[0]\n",
    "    img = cv2.imread(image_path)\n",
    "    for box in result.boxes:\n",
    "        class_id = result.names[box.cls[0].item()]\n",
    "        cords = box.xyxy[0].tolist()\n",
    "        cords = [round(x) for x in cords]\n",
    "        conf = round(box.conf[0].item(), 2)\n",
    "        cv2.rectangle(img, (cords[0], cords[1]), (cords[2], cords[3]), (0, 255, 0), 2)\n",
    "        cv2.putText(img, f\"{class_id} {conf}\", (cords[0], cords[1]), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "        #write predicted image to data/processed/outputs\n",
    "        cv2.imwrite(f\"../data/processed/outputs/{image_path.split('/')[-1]}\", img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/joaotaves/repos/TCC-CDIA/notebooks/../data/processed/frames/frame_3900.jpg: 384x640 3 cars, 6 traffic lights, 26.5ms\n",
      "Speed: 1.8ms preprocess, 26.5ms inference, 12.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[19, 31, 41],\n",
       "        [24, 36, 46],\n",
       "        [38, 48, 58],\n",
       "        ...,\n",
       "        [68, 76, 93],\n",
       "        [60, 70, 87],\n",
       "        [54, 64, 81]],\n",
       "\n",
       "       [[32, 42, 52],\n",
       "        [39, 49, 59],\n",
       "        [49, 59, 69],\n",
       "        ...,\n",
       "        [54, 62, 79],\n",
       "        [55, 65, 82],\n",
       "        [58, 68, 85]],\n",
       "\n",
       "       [[20, 29, 39],\n",
       "        [28, 37, 47],\n",
       "        [30, 39, 49],\n",
       "        ...,\n",
       "        [52, 60, 77],\n",
       "        [56, 66, 83],\n",
       "        [60, 70, 87]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[35, 47, 59],\n",
       "        [37, 49, 61],\n",
       "        [39, 51, 63],\n",
       "        ...,\n",
       "        [30, 30, 36],\n",
       "        [30, 29, 38],\n",
       "        [30, 29, 38]],\n",
       "\n",
       "       [[39, 51, 63],\n",
       "        [39, 51, 63],\n",
       "        [39, 51, 63],\n",
       "        ...,\n",
       "        [30, 30, 36],\n",
       "        [30, 29, 38],\n",
       "        [30, 29, 38]],\n",
       "\n",
       "       [[43, 55, 67],\n",
       "        [41, 53, 65],\n",
       "        [39, 51, 63],\n",
       "        ...,\n",
       "        [30, 30, 36],\n",
       "        [30, 29, 38],\n",
       "        [30, 29, 38]]], dtype=uint8)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_image('../data/processed/frames/frame_3900.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
